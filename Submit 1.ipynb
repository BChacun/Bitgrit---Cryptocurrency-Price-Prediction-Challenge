{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf7984f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Training data loaded.\n",
      "Normalizing features...\n",
      "Features normalized.\n",
      "Building neural network model...\n",
      "Training neural network model...\n",
      "Epoch 1/10000\n",
      "53/67 [======================>.......] - ETA: 0s - loss: 0.8940 - f1_metric: 0.5681 \n",
      "Epoch 1: val_loss improved from inf to 0.68983, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 2s 6ms/step - loss: 0.8866 - f1_metric: 0.5696 - val_loss: 0.6898 - val_f1_metric: 0.6830 - lr: 0.0010\n",
      "Epoch 2/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.8078 - f1_metric: 0.5741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bapti\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7997 - f1_metric: 0.5807 - val_loss: 0.6970 - val_f1_metric: 0.6814 - lr: 0.0010\n",
      "Epoch 3/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.7380 - f1_metric: 0.6237\n",
      "Epoch 3: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.7377 - f1_metric: 0.6289 - val_loss: 0.7000 - val_f1_metric: 0.6719 - lr: 0.0010\n",
      "Epoch 4/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.7369 - f1_metric: 0.6104\n",
      "Epoch 4: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7407 - f1_metric: 0.6017 - val_loss: 0.6996 - val_f1_metric: 0.6592 - lr: 0.0010\n",
      "Epoch 5/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.7135 - f1_metric: 0.6369\n",
      "Epoch 5: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7153 - f1_metric: 0.6385 - val_loss: 0.7004 - val_f1_metric: 0.6540 - lr: 0.0010\n",
      "Epoch 6/10000\n",
      "50/67 [=====================>........] - ETA: 0s - loss: 0.7112 - f1_metric: 0.6387\n",
      "Epoch 6: val_loss did not improve from 0.68983\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7101 - f1_metric: 0.6356 - val_loss: 0.6998 - val_f1_metric: 0.6743 - lr: 0.0010\n",
      "Epoch 7/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.7065 - f1_metric: 0.6470\n",
      "Epoch 7: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7095 - f1_metric: 0.6415 - val_loss: 0.6971 - val_f1_metric: 0.6855 - lr: 2.0000e-04\n",
      "Epoch 8/10000\n",
      "50/67 [=====================>........] - ETA: 0s - loss: 0.7074 - f1_metric: 0.6440\n",
      "Epoch 8: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7056 - f1_metric: 0.6453 - val_loss: 0.6976 - val_f1_metric: 0.6867 - lr: 2.0000e-04\n",
      "Epoch 9/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.7196 - f1_metric: 0.6384\n",
      "Epoch 9: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7194 - f1_metric: 0.6392 - val_loss: 0.6980 - val_f1_metric: 0.6861 - lr: 2.0000e-04\n",
      "Epoch 10/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6958 - f1_metric: 0.6402\n",
      "Epoch 10: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6987 - f1_metric: 0.6392 - val_loss: 0.6974 - val_f1_metric: 0.6842 - lr: 2.0000e-04\n",
      "Epoch 11/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.7031 - f1_metric: 0.6445\n",
      "Epoch 11: val_loss did not improve from 0.68983\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7031 - f1_metric: 0.6478 - val_loss: 0.6983 - val_f1_metric: 0.6848 - lr: 2.0000e-04\n",
      "Epoch 12/10000\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.7063 - f1_metric: 0.6439\n",
      "Epoch 12: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7061 - f1_metric: 0.6448 - val_loss: 0.6975 - val_f1_metric: 0.6896 - lr: 1.0000e-04\n",
      "Epoch 13/10000\n",
      "47/67 [====================>.........] - ETA: 0s - loss: 0.6931 - f1_metric: 0.6574\n",
      "Epoch 13: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6946 - f1_metric: 0.6571 - val_loss: 0.6966 - val_f1_metric: 0.6911 - lr: 1.0000e-04\n",
      "Epoch 14/10000\n",
      "53/67 [======================>.......] - ETA: 0s - loss: 0.7065 - f1_metric: 0.6532\n",
      "Epoch 14: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7035 - f1_metric: 0.6516 - val_loss: 0.6966 - val_f1_metric: 0.6911 - lr: 1.0000e-04\n",
      "Epoch 15/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.7051 - f1_metric: 0.6410\n",
      "Epoch 15: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7084 - f1_metric: 0.6421 - val_loss: 0.6958 - val_f1_metric: 0.6925 - lr: 1.0000e-04\n",
      "Epoch 16/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.7059 - f1_metric: 0.6507\n",
      "Epoch 16: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7055 - f1_metric: 0.6483 - val_loss: 0.6962 - val_f1_metric: 0.6928 - lr: 1.0000e-04\n",
      "Epoch 17/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.7092 - f1_metric: 0.6371\n",
      "Epoch 17: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7068 - f1_metric: 0.6393 - val_loss: 0.6950 - val_f1_metric: 0.6912 - lr: 1.0000e-04\n",
      "Epoch 18/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6914 - f1_metric: 0.6656\n",
      "Epoch 18: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6950 - f1_metric: 0.6615 - val_loss: 0.6945 - val_f1_metric: 0.6899 - lr: 1.0000e-04\n",
      "Epoch 19/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.7036 - f1_metric: 0.6531\n",
      "Epoch 19: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7068 - f1_metric: 0.6504 - val_loss: 0.6939 - val_f1_metric: 0.6914 - lr: 1.0000e-04\n",
      "Epoch 20/10000\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.7029 - f1_metric: 0.6502\n",
      "Epoch 20: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7029 - f1_metric: 0.6502 - val_loss: 0.6938 - val_f1_metric: 0.6914 - lr: 1.0000e-04\n",
      "Epoch 21/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6951 - f1_metric: 0.6596\n",
      "Epoch 21: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6974 - f1_metric: 0.6545 - val_loss: 0.6935 - val_f1_metric: 0.6889 - lr: 1.0000e-04\n",
      "Epoch 22/10000\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.7046 - f1_metric: 0.6534\n",
      "Epoch 22: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7050 - f1_metric: 0.6536 - val_loss: 0.6936 - val_f1_metric: 0.6881 - lr: 1.0000e-04\n",
      "Epoch 23/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.7021 - f1_metric: 0.6432\n",
      "Epoch 23: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7023 - f1_metric: 0.6390 - val_loss: 0.6939 - val_f1_metric: 0.6866 - lr: 1.0000e-04\n",
      "Epoch 24/10000\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.6901 - f1_metric: 0.6811\n",
      "Epoch 24: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6916 - f1_metric: 0.6779 - val_loss: 0.6934 - val_f1_metric: 0.6891 - lr: 1.0000e-04\n",
      "Epoch 25/10000\n",
      "49/67 [====================>.........] - ETA: 0s - loss: 0.6909 - f1_metric: 0.6771\n",
      "Epoch 25: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6948 - f1_metric: 0.6718 - val_loss: 0.6924 - val_f1_metric: 0.6879 - lr: 1.0000e-04\n",
      "Epoch 26/10000\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.6971 - f1_metric: 0.6615\n",
      "Epoch 26: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6968 - f1_metric: 0.6621 - val_loss: 0.6927 - val_f1_metric: 0.6867 - lr: 1.0000e-04\n",
      "Epoch 27/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.7048 - f1_metric: 0.6401\n",
      "Epoch 27: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7010 - f1_metric: 0.6479 - val_loss: 0.6926 - val_f1_metric: 0.6846 - lr: 1.0000e-04\n",
      "Epoch 28/10000\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.6949 - f1_metric: 0.6613\n",
      "Epoch 28: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6958 - f1_metric: 0.6597 - val_loss: 0.6922 - val_f1_metric: 0.6899 - lr: 1.0000e-04\n",
      "Epoch 29/10000\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.6960 - f1_metric: 0.6598\n",
      "Epoch 29: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6980 - f1_metric: 0.6552 - val_loss: 0.6923 - val_f1_metric: 0.6883 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/10000\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.6962 - f1_metric: 0.6642\n",
      "Epoch 30: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6967 - f1_metric: 0.6647 - val_loss: 0.6925 - val_f1_metric: 0.6936 - lr: 1.0000e-04\n",
      "Epoch 31/10000\n",
      "46/67 [===================>..........] - ETA: 0s - loss: 0.6833 - f1_metric: 0.6651\n",
      "Epoch 31: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6860 - f1_metric: 0.6689 - val_loss: 0.6929 - val_f1_metric: 0.6910 - lr: 1.0000e-04\n",
      "Epoch 32/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6937 - f1_metric: 0.6684\n",
      "Epoch 32: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6939 - f1_metric: 0.6687 - val_loss: 0.6925 - val_f1_metric: 0.6879 - lr: 1.0000e-04\n",
      "Epoch 33/10000\n",
      "46/67 [===================>..........] - ETA: 0s - loss: 0.6990 - f1_metric: 0.6580\n",
      "Epoch 33: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6951 - f1_metric: 0.6644 - val_loss: 0.6925 - val_f1_metric: 0.6882 - lr: 1.0000e-04\n",
      "Epoch 34/10000\n",
      "54/67 [=======================>......] - ETA: 0s - loss: 0.7013 - f1_metric: 0.6409\n",
      "Epoch 34: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7019 - f1_metric: 0.6408 - val_loss: 0.6927 - val_f1_metric: 0.6869 - lr: 1.0000e-04\n",
      "Epoch 35/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.6975 - f1_metric: 0.6623\n",
      "Epoch 35: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6992 - f1_metric: 0.6631 - val_loss: 0.6927 - val_f1_metric: 0.6908 - lr: 1.0000e-04\n",
      "Epoch 36/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6998 - f1_metric: 0.6584\n",
      "Epoch 36: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6985 - f1_metric: 0.6603 - val_loss: 0.6925 - val_f1_metric: 0.6885 - lr: 1.0000e-04\n",
      "Epoch 37/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.7011 - f1_metric: 0.6492\n",
      "Epoch 37: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6979 - f1_metric: 0.6519 - val_loss: 0.6914 - val_f1_metric: 0.6871 - lr: 1.0000e-04\n",
      "Epoch 38/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.7070 - f1_metric: 0.6540\n",
      "Epoch 38: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.7051 - f1_metric: 0.6518 - val_loss: 0.6911 - val_f1_metric: 0.6895 - lr: 1.0000e-04\n",
      "Epoch 39/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.7082 - f1_metric: 0.6491\n",
      "Epoch 39: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.7079 - f1_metric: 0.6494 - val_loss: 0.6908 - val_f1_metric: 0.6908 - lr: 1.0000e-04\n",
      "Epoch 40/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6818 - f1_metric: 0.6797\n",
      "Epoch 40: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6847 - f1_metric: 0.6729 - val_loss: 0.6907 - val_f1_metric: 0.6893 - lr: 1.0000e-04\n",
      "Epoch 41/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6973 - f1_metric: 0.6635\n",
      "Epoch 41: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6983 - f1_metric: 0.6572 - val_loss: 0.6909 - val_f1_metric: 0.6901 - lr: 1.0000e-04\n",
      "Epoch 42/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.6935 - f1_metric: 0.6671\n",
      "Epoch 42: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6974 - f1_metric: 0.6589 - val_loss: 0.6906 - val_f1_metric: 0.6923 - lr: 1.0000e-04\n",
      "Epoch 43/10000\n",
      "46/67 [===================>..........] - ETA: 0s - loss: 0.6921 - f1_metric: 0.6606\n",
      "Epoch 43: val_loss did not improve from 0.68983\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6904 - f1_metric: 0.6636 - val_loss: 0.6899 - val_f1_metric: 0.6932 - lr: 1.0000e-04\n",
      "Epoch 44/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.6912 - f1_metric: 0.6643\n",
      "Epoch 44: val_loss improved from 0.68983 to 0.68982, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6884 - f1_metric: 0.6655 - val_loss: 0.6898 - val_f1_metric: 0.6935 - lr: 1.0000e-04\n",
      "Epoch 45/10000\n",
      "50/67 [=====================>........] - ETA: 0s - loss: 0.6950 - f1_metric: 0.6563\n",
      "Epoch 45: val_loss did not improve from 0.68982\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6921 - f1_metric: 0.6624 - val_loss: 0.6898 - val_f1_metric: 0.6888 - lr: 1.0000e-04\n",
      "Epoch 46/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6823 - f1_metric: 0.6723\n",
      "Epoch 46: val_loss improved from 0.68982 to 0.68920, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6880 - f1_metric: 0.6688 - val_loss: 0.6892 - val_f1_metric: 0.6890 - lr: 1.0000e-04\n",
      "Epoch 47/10000\n",
      "53/67 [======================>.......] - ETA: 0s - loss: 0.6904 - f1_metric: 0.6767\n",
      "Epoch 47: val_loss improved from 0.68920 to 0.68903, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6908 - f1_metric: 0.6682 - val_loss: 0.6890 - val_f1_metric: 0.6852 - lr: 1.0000e-04\n",
      "Epoch 48/10000\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.6884 - f1_metric: 0.6650\n",
      "Epoch 48: val_loss improved from 0.68903 to 0.68900, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6892 - f1_metric: 0.6650 - val_loss: 0.6890 - val_f1_metric: 0.6857 - lr: 1.0000e-04\n",
      "Epoch 49/10000\n",
      "47/67 [====================>.........] - ETA: 0s - loss: 0.6880 - f1_metric: 0.6705\n",
      "Epoch 49: val_loss improved from 0.68900 to 0.68829, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6930 - f1_metric: 0.6600 - val_loss: 0.6883 - val_f1_metric: 0.6846 - lr: 1.0000e-04\n",
      "Epoch 50/10000\n",
      "46/67 [===================>..........] - ETA: 0s - loss: 0.6904 - f1_metric: 0.6629\n",
      "Epoch 50: val_loss improved from 0.68829 to 0.68811, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6878 - f1_metric: 0.6664 - val_loss: 0.6881 - val_f1_metric: 0.6883 - lr: 1.0000e-04\n",
      "Epoch 51/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.6893 - f1_metric: 0.6523\n",
      "Epoch 51: val_loss did not improve from 0.68811\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6889 - f1_metric: 0.6627 - val_loss: 0.6885 - val_f1_metric: 0.6860 - lr: 1.0000e-04\n",
      "Epoch 52/10000\n",
      "53/67 [======================>.......] - ETA: 0s - loss: 0.6826 - f1_metric: 0.6730\n",
      "Epoch 52: val_loss did not improve from 0.68811\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6818 - f1_metric: 0.6726 - val_loss: 0.6883 - val_f1_metric: 0.6890 - lr: 1.0000e-04\n",
      "Epoch 53/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.6994 - f1_metric: 0.6423\n",
      "Epoch 53: val_loss improved from 0.68811 to 0.68802, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6953 - f1_metric: 0.6538 - val_loss: 0.6880 - val_f1_metric: 0.6909 - lr: 1.0000e-04\n",
      "Epoch 54/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6909 - f1_metric: 0.6538\n",
      "Epoch 54: val_loss improved from 0.68802 to 0.68783, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6900 - f1_metric: 0.6490 - val_loss: 0.6878 - val_f1_metric: 0.6877 - lr: 1.0000e-04\n",
      "Epoch 55/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6908 - f1_metric: 0.6698\n",
      "Epoch 55: val_loss did not improve from 0.68783\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6879 - f1_metric: 0.6730 - val_loss: 0.6890 - val_f1_metric: 0.6909 - lr: 1.0000e-04\n",
      "Epoch 56/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6886 - f1_metric: 0.6549\n",
      "Epoch 56: val_loss did not improve from 0.68783\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6889 - f1_metric: 0.6581 - val_loss: 0.6885 - val_f1_metric: 0.6871 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6872 - f1_metric: 0.6730\n",
      "Epoch 57: val_loss did not improve from 0.68783\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6884 - f1_metric: 0.6755 - val_loss: 0.6882 - val_f1_metric: 0.6836 - lr: 1.0000e-04\n",
      "Epoch 58/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6931 - f1_metric: 0.6591\n",
      "Epoch 58: val_loss improved from 0.68783 to 0.68761, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6925 - f1_metric: 0.6577 - val_loss: 0.6876 - val_f1_metric: 0.6876 - lr: 1.0000e-04\n",
      "Epoch 59/10000\n",
      "50/67 [=====================>........] - ETA: 0s - loss: 0.6972 - f1_metric: 0.6545\n",
      "Epoch 59: val_loss did not improve from 0.68761\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6970 - f1_metric: 0.6559 - val_loss: 0.6876 - val_f1_metric: 0.6894 - lr: 1.0000e-04\n",
      "Epoch 60/10000\n",
      "49/67 [====================>.........] - ETA: 0s - loss: 0.6922 - f1_metric: 0.6612\n",
      "Epoch 60: val_loss improved from 0.68761 to 0.68721, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6920 - f1_metric: 0.6598 - val_loss: 0.6872 - val_f1_metric: 0.6924 - lr: 1.0000e-04\n",
      "Epoch 61/10000\n",
      "46/67 [===================>..........] - ETA: 0s - loss: 0.6899 - f1_metric: 0.6632\n",
      "Epoch 61: val_loss improved from 0.68721 to 0.68633, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6842 - f1_metric: 0.6744 - val_loss: 0.6863 - val_f1_metric: 0.6935 - lr: 1.0000e-04\n",
      "Epoch 62/10000\n",
      "44/67 [==================>...........] - ETA: 0s - loss: 0.6928 - f1_metric: 0.6649\n",
      "Epoch 62: val_loss improved from 0.68633 to 0.68630, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6882 - f1_metric: 0.6732 - val_loss: 0.6863 - val_f1_metric: 0.6919 - lr: 1.0000e-04\n",
      "Epoch 63/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.6897 - f1_metric: 0.6673\n",
      "Epoch 63: val_loss improved from 0.68630 to 0.68611, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6942 - f1_metric: 0.6602 - val_loss: 0.6861 - val_f1_metric: 0.6911 - lr: 1.0000e-04\n",
      "Epoch 64/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6808 - f1_metric: 0.6738\n",
      "Epoch 64: val_loss improved from 0.68611 to 0.68564, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6799 - f1_metric: 0.6802 - val_loss: 0.6856 - val_f1_metric: 0.6904 - lr: 1.0000e-04\n",
      "Epoch 65/10000\n",
      "54/67 [=======================>......] - ETA: 0s - loss: 0.6820 - f1_metric: 0.6791\n",
      "Epoch 65: val_loss improved from 0.68564 to 0.68534, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6857 - f1_metric: 0.6708 - val_loss: 0.6853 - val_f1_metric: 0.6915 - lr: 1.0000e-04\n",
      "Epoch 66/10000\n",
      "53/67 [======================>.......] - ETA: 0s - loss: 0.6943 - f1_metric: 0.6569\n",
      "Epoch 66: val_loss improved from 0.68534 to 0.68518, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6937 - f1_metric: 0.6554 - val_loss: 0.6852 - val_f1_metric: 0.6901 - lr: 1.0000e-04\n",
      "Epoch 67/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6904 - f1_metric: 0.6614\n",
      "Epoch 67: val_loss improved from 0.68518 to 0.68476, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6866 - f1_metric: 0.6707 - val_loss: 0.6848 - val_f1_metric: 0.6939 - lr: 1.0000e-04\n",
      "Epoch 68/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6862 - f1_metric: 0.6704\n",
      "Epoch 68: val_loss improved from 0.68476 to 0.68441, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6845 - f1_metric: 0.6707 - val_loss: 0.6844 - val_f1_metric: 0.6939 - lr: 1.0000e-04\n",
      "Epoch 69/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6878 - f1_metric: 0.6799\n",
      "Epoch 69: val_loss improved from 0.68441 to 0.68426, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6868 - f1_metric: 0.6776 - val_loss: 0.6843 - val_f1_metric: 0.6924 - lr: 1.0000e-04\n",
      "Epoch 70/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6898 - f1_metric: 0.6664\n",
      "Epoch 70: val_loss did not improve from 0.68426\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6871 - f1_metric: 0.6701 - val_loss: 0.6848 - val_f1_metric: 0.6909 - lr: 1.0000e-04\n",
      "Epoch 71/10000\n",
      "53/67 [======================>.......] - ETA: 0s - loss: 0.6854 - f1_metric: 0.6808\n",
      "Epoch 71: val_loss did not improve from 0.68426\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6837 - f1_metric: 0.6813 - val_loss: 0.6845 - val_f1_metric: 0.6902 - lr: 1.0000e-04\n",
      "Epoch 72/10000\n",
      "54/67 [=======================>......] - ETA: 0s - loss: 0.6985 - f1_metric: 0.6507\n",
      "Epoch 72: val_loss did not improve from 0.68426\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6955 - f1_metric: 0.6529 - val_loss: 0.6843 - val_f1_metric: 0.6923 - lr: 1.0000e-04\n",
      "Epoch 73/10000\n",
      "49/67 [====================>.........] - ETA: 0s - loss: 0.6841 - f1_metric: 0.6855\n",
      "Epoch 73: val_loss did not improve from 0.68426\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6845 - f1_metric: 0.6792 - val_loss: 0.6844 - val_f1_metric: 0.6910 - lr: 1.0000e-04\n",
      "Epoch 74/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6770 - f1_metric: 0.6854\n",
      "Epoch 74: val_loss improved from 0.68426 to 0.68378, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6794 - f1_metric: 0.6800 - val_loss: 0.6838 - val_f1_metric: 0.6928 - lr: 1.0000e-04\n",
      "Epoch 75/10000\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.6798 - f1_metric: 0.6717\n",
      "Epoch 75: val_loss improved from 0.68378 to 0.68372, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6792 - f1_metric: 0.6741 - val_loss: 0.6837 - val_f1_metric: 0.6921 - lr: 1.0000e-04\n",
      "Epoch 76/10000\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.6878 - f1_metric: 0.6705\n",
      "Epoch 76: val_loss improved from 0.68372 to 0.68340, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6884 - f1_metric: 0.6700 - val_loss: 0.6834 - val_f1_metric: 0.6930 - lr: 1.0000e-04\n",
      "Epoch 77/10000\n",
      "47/67 [====================>.........] - ETA: 0s - loss: 0.6897 - f1_metric: 0.6704\n",
      "Epoch 77: val_loss did not improve from 0.68340\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6907 - f1_metric: 0.6644 - val_loss: 0.6837 - val_f1_metric: 0.6968 - lr: 1.0000e-04\n",
      "Epoch 78/10000\n",
      "47/67 [====================>.........] - ETA: 0s - loss: 0.6837 - f1_metric: 0.6682\n",
      "Epoch 78: val_loss improved from 0.68340 to 0.68321, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6835 - f1_metric: 0.6662 - val_loss: 0.6832 - val_f1_metric: 0.6963 - lr: 1.0000e-04\n",
      "Epoch 79/10000\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6813 - f1_metric: 0.6769\n",
      "Epoch 79: val_loss improved from 0.68321 to 0.68279, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6813 - f1_metric: 0.6769 - val_loss: 0.6828 - val_f1_metric: 0.6975 - lr: 1.0000e-04\n",
      "Epoch 80/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6896 - f1_metric: 0.6685\n",
      "Epoch 80: val_loss improved from 0.68279 to 0.68239, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6831 - f1_metric: 0.6784 - val_loss: 0.6824 - val_f1_metric: 0.6970 - lr: 1.0000e-04\n",
      "Epoch 81/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6817 - f1_metric: 0.6739\n",
      "Epoch 81: val_loss did not improve from 0.68239\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6808 - f1_metric: 0.6795 - val_loss: 0.6824 - val_f1_metric: 0.6954 - lr: 1.0000e-04\n",
      "Epoch 82/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6730 - f1_metric: 0.6943\n",
      "Epoch 82: val_loss improved from 0.68239 to 0.68225, saving model to best_nn_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6722 - f1_metric: 0.6918 - val_loss: 0.6823 - val_f1_metric: 0.6969 - lr: 1.0000e-04\n",
      "Epoch 83/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.6848 - f1_metric: 0.6659\n",
      "Epoch 83: val_loss did not improve from 0.68225\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6814 - f1_metric: 0.6699 - val_loss: 0.6825 - val_f1_metric: 0.6970 - lr: 1.0000e-04\n",
      "Epoch 84/10000\n",
      "48/67 [====================>.........] - ETA: 0s - loss: 0.6875 - f1_metric: 0.6767\n",
      "Epoch 84: val_loss improved from 0.68225 to 0.68208, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6811 - f1_metric: 0.6755 - val_loss: 0.6821 - val_f1_metric: 0.6950 - lr: 1.0000e-04\n",
      "Epoch 85/10000\n",
      "48/67 [====================>.........] - ETA: 0s - loss: 0.6867 - f1_metric: 0.6689\n",
      "Epoch 85: val_loss did not improve from 0.68208\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6825 - f1_metric: 0.6766 - val_loss: 0.6822 - val_f1_metric: 0.6920 - lr: 1.0000e-04\n",
      "Epoch 86/10000\n",
      "50/67 [=====================>........] - ETA: 0s - loss: 0.6820 - f1_metric: 0.6752\n",
      "Epoch 86: val_loss improved from 0.68208 to 0.68194, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6845 - f1_metric: 0.6713 - val_loss: 0.6819 - val_f1_metric: 0.6931 - lr: 1.0000e-04\n",
      "Epoch 87/10000\n",
      "50/67 [=====================>........] - ETA: 0s - loss: 0.6883 - f1_metric: 0.6754\n",
      "Epoch 87: val_loss did not improve from 0.68194\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6815 - f1_metric: 0.6826 - val_loss: 0.6828 - val_f1_metric: 0.6939 - lr: 1.0000e-04\n",
      "Epoch 88/10000\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6904 - f1_metric: 0.6645\n",
      "Epoch 88: val_loss did not improve from 0.68194\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6904 - f1_metric: 0.6645 - val_loss: 0.6821 - val_f1_metric: 0.7017 - lr: 1.0000e-04\n",
      "Epoch 89/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6845 - f1_metric: 0.6731\n",
      "Epoch 89: val_loss improved from 0.68194 to 0.68187, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6854 - f1_metric: 0.6748 - val_loss: 0.6819 - val_f1_metric: 0.6987 - lr: 1.0000e-04\n",
      "Epoch 90/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6788 - f1_metric: 0.6751\n",
      "Epoch 90: val_loss improved from 0.68187 to 0.68129, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6790 - f1_metric: 0.6757 - val_loss: 0.6813 - val_f1_metric: 0.6991 - lr: 1.0000e-04\n",
      "Epoch 91/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6755 - f1_metric: 0.6866\n",
      "Epoch 91: val_loss improved from 0.68129 to 0.68031, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6738 - f1_metric: 0.6864 - val_loss: 0.6803 - val_f1_metric: 0.6985 - lr: 1.0000e-04\n",
      "Epoch 92/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6798 - f1_metric: 0.6876\n",
      "Epoch 92: val_loss improved from 0.68031 to 0.67929, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6805 - f1_metric: 0.6864 - val_loss: 0.6793 - val_f1_metric: 0.6986 - lr: 1.0000e-04\n",
      "Epoch 93/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6744 - f1_metric: 0.6887\n",
      "Epoch 93: val_loss improved from 0.67929 to 0.67926, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6733 - f1_metric: 0.6923 - val_loss: 0.6793 - val_f1_metric: 0.6989 - lr: 1.0000e-04\n",
      "Epoch 94/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6767 - f1_metric: 0.6797\n",
      "Epoch 94: val_loss did not improve from 0.67926\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6750 - f1_metric: 0.6807 - val_loss: 0.6794 - val_f1_metric: 0.6992 - lr: 1.0000e-04\n",
      "Epoch 95/10000\n",
      "44/67 [==================>...........] - ETA: 0s - loss: 0.6759 - f1_metric: 0.6875\n",
      "Epoch 95: val_loss did not improve from 0.67926\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6749 - f1_metric: 0.6807 - val_loss: 0.6795 - val_f1_metric: 0.6962 - lr: 1.0000e-04\n",
      "Epoch 96/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.6726 - f1_metric: 0.6867\n",
      "Epoch 96: val_loss did not improve from 0.67926\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6720 - f1_metric: 0.6889 - val_loss: 0.6794 - val_f1_metric: 0.6975 - lr: 1.0000e-04\n",
      "Epoch 97/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6734 - f1_metric: 0.6825\n",
      "Epoch 97: val_loss did not improve from 0.67926\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6757 - f1_metric: 0.6831 - val_loss: 0.6795 - val_f1_metric: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 98/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6791 - f1_metric: 0.6881\n",
      "Epoch 98: val_loss did not improve from 0.67926\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6817 - f1_metric: 0.6850 - val_loss: 0.6793 - val_f1_metric: 0.7019 - lr: 1.0000e-04\n",
      "Epoch 99/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6691 - f1_metric: 0.6955\n",
      "Epoch 99: val_loss improved from 0.67926 to 0.67874, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6682 - f1_metric: 0.6940 - val_loss: 0.6787 - val_f1_metric: 0.7005 - lr: 1.0000e-04\n",
      "Epoch 100/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6853 - f1_metric: 0.6734\n",
      "Epoch 100: val_loss improved from 0.67874 to 0.67837, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6840 - f1_metric: 0.6747 - val_loss: 0.6784 - val_f1_metric: 0.7004 - lr: 1.0000e-04\n",
      "Epoch 101/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6830 - f1_metric: 0.6836\n",
      "Epoch 101: val_loss improved from 0.67837 to 0.67808, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6839 - f1_metric: 0.6790 - val_loss: 0.6781 - val_f1_metric: 0.7010 - lr: 1.0000e-04\n",
      "Epoch 102/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6781 - f1_metric: 0.6768\n",
      "Epoch 102: val_loss improved from 0.67808 to 0.67778, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6820 - f1_metric: 0.6693 - val_loss: 0.6778 - val_f1_metric: 0.6996 - lr: 1.0000e-04\n",
      "Epoch 103/10000\n",
      "50/67 [=====================>........] - ETA: 0s - loss: 0.6758 - f1_metric: 0.6721\n",
      "Epoch 103: val_loss improved from 0.67778 to 0.67768, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6729 - f1_metric: 0.6781 - val_loss: 0.6777 - val_f1_metric: 0.7025 - lr: 1.0000e-04\n",
      "Epoch 104/10000\n",
      "54/67 [=======================>......] - ETA: 0s - loss: 0.6718 - f1_metric: 0.6812\n",
      "Epoch 104: val_loss did not improve from 0.67768\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6766 - f1_metric: 0.6758 - val_loss: 0.6780 - val_f1_metric: 0.7016 - lr: 1.0000e-04\n",
      "Epoch 105/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6663 - f1_metric: 0.6934\n",
      "Epoch 105: val_loss did not improve from 0.67768\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6724 - f1_metric: 0.6820 - val_loss: 0.6779 - val_f1_metric: 0.7010 - lr: 1.0000e-04\n",
      "Epoch 106/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6834 - f1_metric: 0.6761\n",
      "Epoch 106: val_loss did not improve from 0.67768\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6828 - f1_metric: 0.6779 - val_loss: 0.6777 - val_f1_metric: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 107/10000\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.6664 - f1_metric: 0.6879\n",
      "Epoch 107: val_loss improved from 0.67768 to 0.67720, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6666 - f1_metric: 0.6867 - val_loss: 0.6772 - val_f1_metric: 0.7008 - lr: 1.0000e-04\n",
      "Epoch 108/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6687 - f1_metric: 0.6970\n",
      "Epoch 108: val_loss did not improve from 0.67720\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6698 - f1_metric: 0.6953 - val_loss: 0.6773 - val_f1_metric: 0.7024 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/10000\n",
      "46/67 [===================>..........] - ETA: 0s - loss: 0.6748 - f1_metric: 0.6700\n",
      "Epoch 109: val_loss improved from 0.67720 to 0.67649, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6720 - f1_metric: 0.6753 - val_loss: 0.6765 - val_f1_metric: 0.6977 - lr: 1.0000e-04\n",
      "Epoch 110/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6709 - f1_metric: 0.6929\n",
      "Epoch 110: val_loss improved from 0.67649 to 0.67626, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6717 - f1_metric: 0.6886 - val_loss: 0.6763 - val_f1_metric: 0.7004 - lr: 1.0000e-04\n",
      "Epoch 111/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6722 - f1_metric: 0.6911\n",
      "Epoch 111: val_loss improved from 0.67626 to 0.67564, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6722 - f1_metric: 0.6896 - val_loss: 0.6756 - val_f1_metric: 0.7026 - lr: 1.0000e-04\n",
      "Epoch 112/10000\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.6726 - f1_metric: 0.6867\n",
      "Epoch 112: val_loss did not improve from 0.67564\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6729 - f1_metric: 0.6862 - val_loss: 0.6759 - val_f1_metric: 0.6977 - lr: 1.0000e-04\n",
      "Epoch 113/10000\n",
      "47/67 [====================>.........] - ETA: 0s - loss: 0.6675 - f1_metric: 0.6970\n",
      "Epoch 113: val_loss did not improve from 0.67564\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6708 - f1_metric: 0.6918 - val_loss: 0.6760 - val_f1_metric: 0.6982 - lr: 1.0000e-04\n",
      "Epoch 114/10000\n",
      "48/67 [====================>.........] - ETA: 0s - loss: 0.6747 - f1_metric: 0.6921\n",
      "Epoch 114: val_loss did not improve from 0.67564\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6749 - f1_metric: 0.6876 - val_loss: 0.6759 - val_f1_metric: 0.7000 - lr: 1.0000e-04\n",
      "Epoch 115/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6724 - f1_metric: 0.6873\n",
      "Epoch 115: val_loss improved from 0.67564 to 0.67546, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6715 - f1_metric: 0.6872 - val_loss: 0.6755 - val_f1_metric: 0.6985 - lr: 1.0000e-04\n",
      "Epoch 116/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6652 - f1_metric: 0.6891\n",
      "Epoch 116: val_loss did not improve from 0.67546\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6664 - f1_metric: 0.6848 - val_loss: 0.6755 - val_f1_metric: 0.6989 - lr: 1.0000e-04\n",
      "Epoch 117/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6647 - f1_metric: 0.7020\n",
      "Epoch 117: val_loss improved from 0.67546 to 0.67529, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6669 - f1_metric: 0.6966 - val_loss: 0.6753 - val_f1_metric: 0.6991 - lr: 1.0000e-04\n",
      "Epoch 118/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6679 - f1_metric: 0.6926\n",
      "Epoch 118: val_loss improved from 0.67529 to 0.67513, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6675 - f1_metric: 0.6926 - val_loss: 0.6751 - val_f1_metric: 0.6981 - lr: 1.0000e-04\n",
      "Epoch 119/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6829 - f1_metric: 0.6698\n",
      "Epoch 119: val_loss improved from 0.67513 to 0.67500, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6807 - f1_metric: 0.6757 - val_loss: 0.6750 - val_f1_metric: 0.6975 - lr: 1.0000e-04\n",
      "Epoch 120/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6712 - f1_metric: 0.6826\n",
      "Epoch 120: val_loss did not improve from 0.67500\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6706 - f1_metric: 0.6831 - val_loss: 0.6754 - val_f1_metric: 0.6957 - lr: 1.0000e-04\n",
      "Epoch 121/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6726 - f1_metric: 0.6722\n",
      "Epoch 121: val_loss improved from 0.67500 to 0.67485, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6722 - f1_metric: 0.6746 - val_loss: 0.6749 - val_f1_metric: 0.6997 - lr: 1.0000e-04\n",
      "Epoch 122/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6645 - f1_metric: 0.6887\n",
      "Epoch 122: val_loss did not improve from 0.67485\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6649 - f1_metric: 0.6897 - val_loss: 0.6749 - val_f1_metric: 0.7029 - lr: 1.0000e-04\n",
      "Epoch 123/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6695 - f1_metric: 0.6707\n",
      "Epoch 123: val_loss did not improve from 0.67485\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6685 - f1_metric: 0.6753 - val_loss: 0.6754 - val_f1_metric: 0.6987 - lr: 1.0000e-04\n",
      "Epoch 124/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6709 - f1_metric: 0.6811\n",
      "Epoch 124: val_loss did not improve from 0.67485\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6707 - f1_metric: 0.6806 - val_loss: 0.6754 - val_f1_metric: 0.6989 - lr: 1.0000e-04\n",
      "Epoch 125/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6653 - f1_metric: 0.6824\n",
      "Epoch 125: val_loss improved from 0.67485 to 0.67469, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6649 - f1_metric: 0.6869 - val_loss: 0.6747 - val_f1_metric: 0.7009 - lr: 1.0000e-04\n",
      "Epoch 126/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6686 - f1_metric: 0.6888\n",
      "Epoch 126: val_loss improved from 0.67469 to 0.67443, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6682 - f1_metric: 0.6890 - val_loss: 0.6744 - val_f1_metric: 0.7008 - lr: 1.0000e-04\n",
      "Epoch 127/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6744 - f1_metric: 0.6665\n",
      "Epoch 127: val_loss did not improve from 0.67443\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6711 - f1_metric: 0.6731 - val_loss: 0.6751 - val_f1_metric: 0.6993 - lr: 1.0000e-04\n",
      "Epoch 128/10000\n",
      "54/67 [=======================>......] - ETA: 0s - loss: 0.6669 - f1_metric: 0.6888\n",
      "Epoch 128: val_loss did not improve from 0.67443\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6688 - f1_metric: 0.6864 - val_loss: 0.6752 - val_f1_metric: 0.6979 - lr: 1.0000e-04\n",
      "Epoch 129/10000\n",
      "53/67 [======================>.......] - ETA: 0s - loss: 0.6640 - f1_metric: 0.6973\n",
      "Epoch 129: val_loss did not improve from 0.67443\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6673 - f1_metric: 0.6928 - val_loss: 0.6751 - val_f1_metric: 0.6982 - lr: 1.0000e-04\n",
      "Epoch 130/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.6757 - f1_metric: 0.6757\n",
      "Epoch 130: val_loss did not improve from 0.67443\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6700 - f1_metric: 0.6812 - val_loss: 0.6746 - val_f1_metric: 0.7035 - lr: 1.0000e-04\n",
      "Epoch 131/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6593 - f1_metric: 0.7073\n",
      "Epoch 131: val_loss improved from 0.67443 to 0.67398, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6593 - f1_metric: 0.7047 - val_loss: 0.6740 - val_f1_metric: 0.7027 - lr: 1.0000e-04\n",
      "Epoch 132/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6628 - f1_metric: 0.6992\n",
      "Epoch 132: val_loss did not improve from 0.67398\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6651 - f1_metric: 0.6955 - val_loss: 0.6743 - val_f1_metric: 0.6999 - lr: 1.0000e-04\n",
      "Epoch 133/10000\n",
      "50/67 [=====================>........] - ETA: 0s - loss: 0.6678 - f1_metric: 0.6775\n",
      "Epoch 133: val_loss improved from 0.67398 to 0.67393, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6657 - f1_metric: 0.6853 - val_loss: 0.6739 - val_f1_metric: 0.6968 - lr: 1.0000e-04\n",
      "Epoch 134/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6671 - f1_metric: 0.6846\n",
      "Epoch 134: val_loss improved from 0.67393 to 0.67354, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6689 - f1_metric: 0.6832 - val_loss: 0.6735 - val_f1_metric: 0.7015 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6732 - f1_metric: 0.6809\n",
      "Epoch 135: val_loss did not improve from 0.67354\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6701 - f1_metric: 0.6871 - val_loss: 0.6741 - val_f1_metric: 0.7009 - lr: 1.0000e-04\n",
      "Epoch 136/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6639 - f1_metric: 0.6860\n",
      "Epoch 136: val_loss did not improve from 0.67354\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6630 - f1_metric: 0.6885 - val_loss: 0.6739 - val_f1_metric: 0.7005 - lr: 1.0000e-04\n",
      "Epoch 137/10000\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6547 - f1_metric: 0.6952\n",
      "Epoch 137: val_loss did not improve from 0.67354\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6547 - f1_metric: 0.6952 - val_loss: 0.6740 - val_f1_metric: 0.6989 - lr: 1.0000e-04\n",
      "Epoch 138/10000\n",
      "54/67 [=======================>......] - ETA: 0s - loss: 0.6610 - f1_metric: 0.6981\n",
      "Epoch 138: val_loss improved from 0.67354 to 0.67345, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6626 - f1_metric: 0.7002 - val_loss: 0.6734 - val_f1_metric: 0.7004 - lr: 1.0000e-04\n",
      "Epoch 139/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.6640 - f1_metric: 0.6841\n",
      "Epoch 139: val_loss improved from 0.67345 to 0.67278, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6650 - f1_metric: 0.6816 - val_loss: 0.6728 - val_f1_metric: 0.6994 - lr: 1.0000e-04\n",
      "Epoch 140/10000\n",
      "53/67 [======================>.......] - ETA: 0s - loss: 0.6622 - f1_metric: 0.6949\n",
      "Epoch 140: val_loss did not improve from 0.67278\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6614 - f1_metric: 0.6907 - val_loss: 0.6729 - val_f1_metric: 0.6974 - lr: 1.0000e-04\n",
      "Epoch 141/10000\n",
      "49/67 [====================>.........] - ETA: 0s - loss: 0.6606 - f1_metric: 0.6853\n",
      "Epoch 141: val_loss improved from 0.67278 to 0.67258, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6636 - f1_metric: 0.6793 - val_loss: 0.6726 - val_f1_metric: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 142/10000\n",
      "46/67 [===================>..........] - ETA: 0s - loss: 0.6547 - f1_metric: 0.7015\n",
      "Epoch 142: val_loss did not improve from 0.67258\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6544 - f1_metric: 0.7001 - val_loss: 0.6728 - val_f1_metric: 0.6979 - lr: 1.0000e-04\n",
      "Epoch 143/10000\n",
      "48/67 [====================>.........] - ETA: 0s - loss: 0.6548 - f1_metric: 0.6909\n",
      "Epoch 143: val_loss improved from 0.67258 to 0.67222, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6534 - f1_metric: 0.6973 - val_loss: 0.6722 - val_f1_metric: 0.6977 - lr: 1.0000e-04\n",
      "Epoch 144/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6655 - f1_metric: 0.6870\n",
      "Epoch 144: val_loss improved from 0.67222 to 0.67210, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6631 - f1_metric: 0.6866 - val_loss: 0.6721 - val_f1_metric: 0.7034 - lr: 1.0000e-04\n",
      "Epoch 145/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6581 - f1_metric: 0.7018\n",
      "Epoch 145: val_loss improved from 0.67210 to 0.67179, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6610 - f1_metric: 0.6991 - val_loss: 0.6718 - val_f1_metric: 0.6998 - lr: 1.0000e-04\n",
      "Epoch 146/10000\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.6611 - f1_metric: 0.6950\n",
      "Epoch 146: val_loss did not improve from 0.67179\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6624 - f1_metric: 0.6941 - val_loss: 0.6723 - val_f1_metric: 0.7017 - lr: 1.0000e-04\n",
      "Epoch 147/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6619 - f1_metric: 0.6936\n",
      "Epoch 147: val_loss did not improve from 0.67179\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6623 - f1_metric: 0.6914 - val_loss: 0.6723 - val_f1_metric: 0.7007 - lr: 1.0000e-04\n",
      "Epoch 148/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6562 - f1_metric: 0.7010\n",
      "Epoch 148: val_loss improved from 0.67179 to 0.67147, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6545 - f1_metric: 0.7031 - val_loss: 0.6715 - val_f1_metric: 0.7006 - lr: 1.0000e-04\n",
      "Epoch 149/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6674 - f1_metric: 0.6764\n",
      "Epoch 149: val_loss did not improve from 0.67147\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6656 - f1_metric: 0.6814 - val_loss: 0.6715 - val_f1_metric: 0.7035 - lr: 1.0000e-04\n",
      "Epoch 150/10000\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.6533 - f1_metric: 0.6943\n",
      "Epoch 150: val_loss improved from 0.67147 to 0.67118, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6525 - f1_metric: 0.6944 - val_loss: 0.6712 - val_f1_metric: 0.7049 - lr: 1.0000e-04\n",
      "Epoch 151/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6565 - f1_metric: 0.6902\n",
      "Epoch 151: val_loss improved from 0.67118 to 0.67075, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6547 - f1_metric: 0.6934 - val_loss: 0.6707 - val_f1_metric: 0.7069 - lr: 1.0000e-04\n",
      "Epoch 152/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6620 - f1_metric: 0.6846\n",
      "Epoch 152: val_loss improved from 0.67075 to 0.67063, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6580 - f1_metric: 0.6895 - val_loss: 0.6706 - val_f1_metric: 0.7067 - lr: 1.0000e-04\n",
      "Epoch 153/10000\n",
      "64/67 [===========================>..] - ETA: 0s - loss: 0.6555 - f1_metric: 0.7017\n",
      "Epoch 153: val_loss improved from 0.67063 to 0.66987, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6563 - f1_metric: 0.6986 - val_loss: 0.6699 - val_f1_metric: 0.7077 - lr: 1.0000e-04\n",
      "Epoch 154/10000\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.6557 - f1_metric: 0.6877\n",
      "Epoch 154: val_loss improved from 0.66987 to 0.66984, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6551 - f1_metric: 0.6897 - val_loss: 0.6698 - val_f1_metric: 0.7092 - lr: 1.0000e-04\n",
      "Epoch 155/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6542 - f1_metric: 0.6939\n",
      "Epoch 155: val_loss improved from 0.66984 to 0.66948, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6561 - f1_metric: 0.6910 - val_loss: 0.6695 - val_f1_metric: 0.7081 - lr: 1.0000e-04\n",
      "Epoch 156/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6622 - f1_metric: 0.6926\n",
      "Epoch 156: val_loss improved from 0.66948 to 0.66919, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6605 - f1_metric: 0.6952 - val_loss: 0.6692 - val_f1_metric: 0.7053 - lr: 1.0000e-04\n",
      "Epoch 157/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6539 - f1_metric: 0.7023\n",
      "Epoch 157: val_loss improved from 0.66919 to 0.66868, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6527 - f1_metric: 0.6998 - val_loss: 0.6687 - val_f1_metric: 0.7064 - lr: 1.0000e-04\n",
      "Epoch 158/10000\n",
      "53/67 [======================>.......] - ETA: 0s - loss: 0.6587 - f1_metric: 0.6871\n",
      "Epoch 158: val_loss improved from 0.66868 to 0.66819, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.6533 - f1_metric: 0.6919 - val_loss: 0.6682 - val_f1_metric: 0.7073 - lr: 1.0000e-04\n",
      "Epoch 159/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6493 - f1_metric: 0.6883\n",
      "Epoch 159: val_loss improved from 0.66819 to 0.66801, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6472 - f1_metric: 0.6936 - val_loss: 0.6680 - val_f1_metric: 0.7052 - lr: 1.0000e-04\n",
      "Epoch 160/10000\n",
      "65/67 [============================>.] - ETA: 0s - loss: 0.6616 - f1_metric: 0.6950\n",
      "Epoch 160: val_loss improved from 0.66801 to 0.66771, saving model to best_nn_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 4ms/step - loss: 0.6630 - f1_metric: 0.6942 - val_loss: 0.6677 - val_f1_metric: 0.7062 - lr: 1.0000e-04\n",
      "Epoch 161/10000\n",
      "53/67 [======================>.......] - ETA: 0s - loss: 0.6628 - f1_metric: 0.6783\n",
      "Epoch 161: val_loss did not improve from 0.66771\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6605 - f1_metric: 0.6826 - val_loss: 0.6681 - val_f1_metric: 0.7070 - lr: 1.0000e-04\n",
      "Epoch 162/10000\n",
      "49/67 [====================>.........] - ETA: 0s - loss: 0.6539 - f1_metric: 0.6942\n",
      "Epoch 162: val_loss did not improve from 0.66771\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6535 - f1_metric: 0.6959 - val_loss: 0.6680 - val_f1_metric: 0.7070 - lr: 1.0000e-04\n",
      "Epoch 163/10000\n",
      "46/67 [===================>..........] - ETA: 0s - loss: 0.6530 - f1_metric: 0.7004\n",
      "Epoch 163: val_loss did not improve from 0.66771\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6573 - f1_metric: 0.6932 - val_loss: 0.6680 - val_f1_metric: 0.7057 - lr: 1.0000e-04\n",
      "Epoch 164/10000\n",
      "48/67 [====================>.........] - ETA: 0s - loss: 0.6539 - f1_metric: 0.6923\n",
      "Epoch 164: val_loss improved from 0.66771 to 0.66760, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6521 - f1_metric: 0.6902 - val_loss: 0.6676 - val_f1_metric: 0.7066 - lr: 1.0000e-04\n",
      "Epoch 165/10000\n",
      "49/67 [====================>.........] - ETA: 0s - loss: 0.6613 - f1_metric: 0.7007\n",
      "Epoch 165: val_loss improved from 0.66760 to 0.66759, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6571 - f1_metric: 0.7024 - val_loss: 0.6676 - val_f1_metric: 0.7039 - lr: 1.0000e-04\n",
      "Epoch 166/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6593 - f1_metric: 0.6829\n",
      "Epoch 166: val_loss did not improve from 0.66759\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6570 - f1_metric: 0.6866 - val_loss: 0.6685 - val_f1_metric: 0.7066 - lr: 1.0000e-04\n",
      "Epoch 167/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.6503 - f1_metric: 0.6976\n",
      "Epoch 167: val_loss did not improve from 0.66759\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6469 - f1_metric: 0.6992 - val_loss: 0.6680 - val_f1_metric: 0.7057 - lr: 1.0000e-04\n",
      "Epoch 168/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.6564 - f1_metric: 0.6909\n",
      "Epoch 168: val_loss did not improve from 0.66759\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6568 - f1_metric: 0.6921 - val_loss: 0.6677 - val_f1_metric: 0.7029 - lr: 1.0000e-04\n",
      "Epoch 169/10000\n",
      "49/67 [====================>.........] - ETA: 0s - loss: 0.6485 - f1_metric: 0.7046\n",
      "Epoch 169: val_loss did not improve from 0.66759\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6502 - f1_metric: 0.7012 - val_loss: 0.6679 - val_f1_metric: 0.7045 - lr: 1.0000e-04\n",
      "Epoch 170/10000\n",
      "54/67 [=======================>......] - ETA: 0s - loss: 0.6514 - f1_metric: 0.6975\n",
      "Epoch 170: val_loss improved from 0.66759 to 0.66747, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6516 - f1_metric: 0.6978 - val_loss: 0.6675 - val_f1_metric: 0.7030 - lr: 1.0000e-04\n",
      "Epoch 171/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6544 - f1_metric: 0.6941\n",
      "Epoch 171: val_loss did not improve from 0.66747\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6539 - f1_metric: 0.6976 - val_loss: 0.6679 - val_f1_metric: 0.7029 - lr: 1.0000e-04\n",
      "Epoch 172/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6511 - f1_metric: 0.7048\n",
      "Epoch 172: val_loss did not improve from 0.66747\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6510 - f1_metric: 0.7016 - val_loss: 0.6681 - val_f1_metric: 0.7013 - lr: 1.0000e-04\n",
      "Epoch 173/10000\n",
      "48/67 [====================>.........] - ETA: 0s - loss: 0.6541 - f1_metric: 0.6914\n",
      "Epoch 173: val_loss did not improve from 0.66747\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6565 - f1_metric: 0.6824 - val_loss: 0.6681 - val_f1_metric: 0.7006 - lr: 1.0000e-04\n",
      "Epoch 174/10000\n",
      "43/67 [==================>...........] - ETA: 0s - loss: 0.6566 - f1_metric: 0.6913\n",
      "Epoch 174: val_loss did not improve from 0.66747\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6603 - f1_metric: 0.6881 - val_loss: 0.6680 - val_f1_metric: 0.7013 - lr: 1.0000e-04\n",
      "Epoch 175/10000\n",
      "47/67 [====================>.........] - ETA: 0s - loss: 0.6442 - f1_metric: 0.7025\n",
      "Epoch 175: val_loss improved from 0.66747 to 0.66712, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6440 - f1_metric: 0.7029 - val_loss: 0.6671 - val_f1_metric: 0.7016 - lr: 1.0000e-04\n",
      "Epoch 176/10000\n",
      "46/67 [===================>..........] - ETA: 0s - loss: 0.6388 - f1_metric: 0.7139\n",
      "Epoch 176: val_loss did not improve from 0.66712\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6433 - f1_metric: 0.7091 - val_loss: 0.6675 - val_f1_metric: 0.6994 - lr: 1.0000e-04\n",
      "Epoch 177/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.6569 - f1_metric: 0.6891\n",
      "Epoch 177: val_loss improved from 0.66712 to 0.66706, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6545 - f1_metric: 0.6915 - val_loss: 0.6671 - val_f1_metric: 0.7040 - lr: 1.0000e-04\n",
      "Epoch 178/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6456 - f1_metric: 0.6965\n",
      "Epoch 178: val_loss improved from 0.66706 to 0.66689, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6483 - f1_metric: 0.6961 - val_loss: 0.6669 - val_f1_metric: 0.7087 - lr: 1.0000e-04\n",
      "Epoch 179/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6506 - f1_metric: 0.7115\n",
      "Epoch 179: val_loss improved from 0.66689 to 0.66645, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6559 - f1_metric: 0.7003 - val_loss: 0.6665 - val_f1_metric: 0.7114 - lr: 1.0000e-04\n",
      "Epoch 180/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6517 - f1_metric: 0.6951\n",
      "Epoch 180: val_loss improved from 0.66645 to 0.66625, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6543 - f1_metric: 0.6895 - val_loss: 0.6662 - val_f1_metric: 0.7065 - lr: 1.0000e-04\n",
      "Epoch 181/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6379 - f1_metric: 0.7170\n",
      "Epoch 181: val_loss improved from 0.66625 to 0.66617, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6410 - f1_metric: 0.7107 - val_loss: 0.6662 - val_f1_metric: 0.7066 - lr: 1.0000e-04\n",
      "Epoch 182/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6518 - f1_metric: 0.6859\n",
      "Epoch 182: val_loss improved from 0.66617 to 0.66565, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6510 - f1_metric: 0.6882 - val_loss: 0.6656 - val_f1_metric: 0.7049 - lr: 1.0000e-04\n",
      "Epoch 183/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6452 - f1_metric: 0.6984\n",
      "Epoch 183: val_loss improved from 0.66565 to 0.66550, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6486 - f1_metric: 0.6996 - val_loss: 0.6655 - val_f1_metric: 0.7049 - lr: 1.0000e-04\n",
      "Epoch 184/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6532 - f1_metric: 0.6908\n",
      "Epoch 184: val_loss improved from 0.66550 to 0.66478, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6531 - f1_metric: 0.6888 - val_loss: 0.6648 - val_f1_metric: 0.7070 - lr: 1.0000e-04\n",
      "Epoch 185/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6554 - f1_metric: 0.6864\n",
      "Epoch 185: val_loss did not improve from 0.66478\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6513 - f1_metric: 0.6937 - val_loss: 0.6651 - val_f1_metric: 0.7032 - lr: 1.0000e-04\n",
      "Epoch 186/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6465 - f1_metric: 0.6959\n",
      "Epoch 186: val_loss did not improve from 0.66478\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6501 - f1_metric: 0.6902 - val_loss: 0.6655 - val_f1_metric: 0.7062 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/10000\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.6414 - f1_metric: 0.7112\n",
      "Epoch 187: val_loss improved from 0.66478 to 0.66457, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6402 - f1_metric: 0.7116 - val_loss: 0.6646 - val_f1_metric: 0.7080 - lr: 1.0000e-04\n",
      "Epoch 188/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6515 - f1_metric: 0.6813\n",
      "Epoch 188: val_loss improved from 0.66457 to 0.66456, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6469 - f1_metric: 0.6910 - val_loss: 0.6646 - val_f1_metric: 0.7056 - lr: 1.0000e-04\n",
      "Epoch 189/10000\n",
      "54/67 [=======================>......] - ETA: 0s - loss: 0.6460 - f1_metric: 0.6939\n",
      "Epoch 189: val_loss improved from 0.66456 to 0.66447, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6450 - f1_metric: 0.6982 - val_loss: 0.6645 - val_f1_metric: 0.7055 - lr: 1.0000e-04\n",
      "Epoch 190/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6501 - f1_metric: 0.6921\n",
      "Epoch 190: val_loss improved from 0.66447 to 0.66394, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6482 - f1_metric: 0.6958 - val_loss: 0.6639 - val_f1_metric: 0.7055 - lr: 1.0000e-04\n",
      "Epoch 191/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6348 - f1_metric: 0.7079\n",
      "Epoch 191: val_loss did not improve from 0.66394\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6362 - f1_metric: 0.7030 - val_loss: 0.6641 - val_f1_metric: 0.7055 - lr: 1.0000e-04\n",
      "Epoch 192/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6405 - f1_metric: 0.7006\n",
      "Epoch 192: val_loss did not improve from 0.66394\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6436 - f1_metric: 0.6964 - val_loss: 0.6640 - val_f1_metric: 0.7083 - lr: 1.0000e-04\n",
      "Epoch 193/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6455 - f1_metric: 0.6993\n",
      "Epoch 193: val_loss did not improve from 0.66394\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6455 - f1_metric: 0.7004 - val_loss: 0.6647 - val_f1_metric: 0.7083 - lr: 1.0000e-04\n",
      "Epoch 194/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6328 - f1_metric: 0.7093\n",
      "Epoch 194: val_loss improved from 0.66394 to 0.66379, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6319 - f1_metric: 0.7112 - val_loss: 0.6638 - val_f1_metric: 0.7077 - lr: 1.0000e-04\n",
      "Epoch 195/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6448 - f1_metric: 0.6865\n",
      "Epoch 195: val_loss improved from 0.66379 to 0.66321, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6426 - f1_metric: 0.6926 - val_loss: 0.6632 - val_f1_metric: 0.7077 - lr: 1.0000e-04\n",
      "Epoch 196/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6461 - f1_metric: 0.6898\n",
      "Epoch 196: val_loss improved from 0.66321 to 0.66277, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6477 - f1_metric: 0.6835 - val_loss: 0.6628 - val_f1_metric: 0.7066 - lr: 1.0000e-04\n",
      "Epoch 197/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6356 - f1_metric: 0.7099\n",
      "Epoch 197: val_loss improved from 0.66277 to 0.66267, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6392 - f1_metric: 0.7011 - val_loss: 0.6627 - val_f1_metric: 0.7103 - lr: 1.0000e-04\n",
      "Epoch 198/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6433 - f1_metric: 0.7003\n",
      "Epoch 198: val_loss did not improve from 0.66267\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6448 - f1_metric: 0.6947 - val_loss: 0.6628 - val_f1_metric: 0.7100 - lr: 1.0000e-04\n",
      "Epoch 199/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6439 - f1_metric: 0.6993\n",
      "Epoch 199: val_loss improved from 0.66267 to 0.66241, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6484 - f1_metric: 0.6969 - val_loss: 0.6624 - val_f1_metric: 0.7091 - lr: 1.0000e-04\n",
      "Epoch 200/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6495 - f1_metric: 0.6946\n",
      "Epoch 200: val_loss improved from 0.66241 to 0.66136, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6469 - f1_metric: 0.7006 - val_loss: 0.6614 - val_f1_metric: 0.7036 - lr: 1.0000e-04\n",
      "Epoch 201/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6465 - f1_metric: 0.6933\n",
      "Epoch 201: val_loss did not improve from 0.66136\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6473 - f1_metric: 0.6918 - val_loss: 0.6618 - val_f1_metric: 0.7036 - lr: 1.0000e-04\n",
      "Epoch 202/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6422 - f1_metric: 0.6990\n",
      "Epoch 202: val_loss did not improve from 0.66136\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6430 - f1_metric: 0.7002 - val_loss: 0.6625 - val_f1_metric: 0.7050 - lr: 1.0000e-04\n",
      "Epoch 203/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6337 - f1_metric: 0.7152\n",
      "Epoch 203: val_loss did not improve from 0.66136\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6344 - f1_metric: 0.7096 - val_loss: 0.6621 - val_f1_metric: 0.7062 - lr: 1.0000e-04\n",
      "Epoch 204/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6333 - f1_metric: 0.7001\n",
      "Epoch 204: val_loss did not improve from 0.66136\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6334 - f1_metric: 0.7006 - val_loss: 0.6615 - val_f1_metric: 0.6997 - lr: 1.0000e-04\n",
      "Epoch 205/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6423 - f1_metric: 0.7040\n",
      "Epoch 205: val_loss improved from 0.66136 to 0.66087, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6434 - f1_metric: 0.7004 - val_loss: 0.6609 - val_f1_metric: 0.7016 - lr: 1.0000e-04\n",
      "Epoch 206/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6302 - f1_metric: 0.7108\n",
      "Epoch 206: val_loss did not improve from 0.66087\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6324 - f1_metric: 0.7118 - val_loss: 0.6610 - val_f1_metric: 0.7036 - lr: 1.0000e-04\n",
      "Epoch 207/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6424 - f1_metric: 0.6965\n",
      "Epoch 207: val_loss did not improve from 0.66087\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6435 - f1_metric: 0.6975 - val_loss: 0.6610 - val_f1_metric: 0.7032 - lr: 1.0000e-04\n",
      "Epoch 208/10000\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.6475 - f1_metric: 0.6929\n",
      "Epoch 208: val_loss did not improve from 0.66087\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6469 - f1_metric: 0.6939 - val_loss: 0.6612 - val_f1_metric: 0.7078 - lr: 1.0000e-04\n",
      "Epoch 209/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6389 - f1_metric: 0.7045\n",
      "Epoch 209: val_loss did not improve from 0.66087\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6402 - f1_metric: 0.7039 - val_loss: 0.6610 - val_f1_metric: 0.7089 - lr: 1.0000e-04\n",
      "Epoch 210/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6429 - f1_metric: 0.6995\n",
      "Epoch 210: val_loss improved from 0.66087 to 0.66015, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6393 - f1_metric: 0.7053 - val_loss: 0.6602 - val_f1_metric: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 211/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6491 - f1_metric: 0.6892\n",
      "Epoch 211: val_loss did not improve from 0.66015\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6459 - f1_metric: 0.6933 - val_loss: 0.6607 - val_f1_metric: 0.7019 - lr: 1.0000e-04\n",
      "Epoch 212/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6369 - f1_metric: 0.6975\n",
      "Epoch 212: val_loss did not improve from 0.66015\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6343 - f1_metric: 0.7042 - val_loss: 0.6602 - val_f1_metric: 0.7036 - lr: 1.0000e-04\n",
      "Epoch 213/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6201 - f1_metric: 0.7147\n",
      "Epoch 213: val_loss improved from 0.66015 to 0.65969, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6227 - f1_metric: 0.7105 - val_loss: 0.6597 - val_f1_metric: 0.7015 - lr: 1.0000e-04\n",
      "Epoch 214/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6337 - f1_metric: 0.6964\n",
      "Epoch 214: val_loss improved from 0.65969 to 0.65938, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6336 - f1_metric: 0.7005 - val_loss: 0.6594 - val_f1_metric: 0.7017 - lr: 1.0000e-04\n",
      "Epoch 215/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6399 - f1_metric: 0.6995\n",
      "Epoch 215: val_loss did not improve from 0.65938\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6382 - f1_metric: 0.7001 - val_loss: 0.6596 - val_f1_metric: 0.6991 - lr: 1.0000e-04\n",
      "Epoch 216/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6405 - f1_metric: 0.7017\n",
      "Epoch 216: val_loss improved from 0.65938 to 0.65909, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6420 - f1_metric: 0.7001 - val_loss: 0.6591 - val_f1_metric: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 217/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6345 - f1_metric: 0.7044\n",
      "Epoch 217: val_loss did not improve from 0.65909\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6359 - f1_metric: 0.7049 - val_loss: 0.6597 - val_f1_metric: 0.7015 - lr: 1.0000e-04\n",
      "Epoch 218/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6280 - f1_metric: 0.7049\n",
      "Epoch 218: val_loss did not improve from 0.65909\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6293 - f1_metric: 0.7027 - val_loss: 0.6599 - val_f1_metric: 0.7065 - lr: 1.0000e-04\n",
      "Epoch 219/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6284 - f1_metric: 0.7237\n",
      "Epoch 219: val_loss did not improve from 0.65909\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6296 - f1_metric: 0.7225 - val_loss: 0.6599 - val_f1_metric: 0.7044 - lr: 1.0000e-04\n",
      "Epoch 220/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6311 - f1_metric: 0.7105\n",
      "Epoch 220: val_loss did not improve from 0.65909\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6319 - f1_metric: 0.7093 - val_loss: 0.6601 - val_f1_metric: 0.7101 - lr: 1.0000e-04\n",
      "Epoch 221/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6346 - f1_metric: 0.7012\n",
      "Epoch 221: val_loss did not improve from 0.65909\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6314 - f1_metric: 0.7070 - val_loss: 0.6603 - val_f1_metric: 0.7080 - lr: 1.0000e-04\n",
      "Epoch 222/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6220 - f1_metric: 0.7198\n",
      "Epoch 222: val_loss did not improve from 0.65909\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6240 - f1_metric: 0.7136 - val_loss: 0.6603 - val_f1_metric: 0.7098 - lr: 1.0000e-04\n",
      "Epoch 223/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6421 - f1_metric: 0.6962\n",
      "Epoch 223: val_loss did not improve from 0.65909\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6409 - f1_metric: 0.6970 - val_loss: 0.6602 - val_f1_metric: 0.7080 - lr: 1.0000e-04\n",
      "Epoch 224/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6382 - f1_metric: 0.7117\n",
      "Epoch 224: val_loss did not improve from 0.65909\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6390 - f1_metric: 0.7099 - val_loss: 0.6592 - val_f1_metric: 0.7065 - lr: 1.0000e-04\n",
      "Epoch 225/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6277 - f1_metric: 0.7120\n",
      "Epoch 225: val_loss improved from 0.65909 to 0.65889, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6319 - f1_metric: 0.7078 - val_loss: 0.6589 - val_f1_metric: 0.7057 - lr: 1.0000e-04\n",
      "Epoch 226/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6417 - f1_metric: 0.7088\n",
      "Epoch 226: val_loss did not improve from 0.65889\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6386 - f1_metric: 0.7138 - val_loss: 0.6590 - val_f1_metric: 0.7047 - lr: 1.0000e-04\n",
      "Epoch 227/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6234 - f1_metric: 0.7182\n",
      "Epoch 227: val_loss improved from 0.65889 to 0.65842, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6240 - f1_metric: 0.7175 - val_loss: 0.6584 - val_f1_metric: 0.7017 - lr: 1.0000e-04\n",
      "Epoch 228/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6285 - f1_metric: 0.7124\n",
      "Epoch 228: val_loss did not improve from 0.65842\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6289 - f1_metric: 0.7106 - val_loss: 0.6584 - val_f1_metric: 0.7028 - lr: 1.0000e-04\n",
      "Epoch 229/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6366 - f1_metric: 0.7025\n",
      "Epoch 229: val_loss did not improve from 0.65842\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6340 - f1_metric: 0.7009 - val_loss: 0.6585 - val_f1_metric: 0.7033 - lr: 1.0000e-04\n",
      "Epoch 230/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6265 - f1_metric: 0.7123\n",
      "Epoch 230: val_loss did not improve from 0.65842\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6281 - f1_metric: 0.7080 - val_loss: 0.6591 - val_f1_metric: 0.7018 - lr: 1.0000e-04\n",
      "Epoch 231/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6357 - f1_metric: 0.6936\n",
      "Epoch 231: val_loss did not improve from 0.65842\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6364 - f1_metric: 0.6944 - val_loss: 0.6587 - val_f1_metric: 0.7018 - lr: 1.0000e-04\n",
      "Epoch 232/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6236 - f1_metric: 0.7157\n",
      "Epoch 232: val_loss did not improve from 0.65842\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6215 - f1_metric: 0.7207 - val_loss: 0.6587 - val_f1_metric: 0.7004 - lr: 1.0000e-04\n",
      "Epoch 233/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6273 - f1_metric: 0.7102\n",
      "Epoch 233: val_loss improved from 0.65842 to 0.65800, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6269 - f1_metric: 0.7078 - val_loss: 0.6580 - val_f1_metric: 0.7037 - lr: 1.0000e-04\n",
      "Epoch 234/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6257 - f1_metric: 0.7067\n",
      "Epoch 234: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6263 - f1_metric: 0.7038 - val_loss: 0.6586 - val_f1_metric: 0.7046 - lr: 1.0000e-04\n",
      "Epoch 235/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6348 - f1_metric: 0.7061\n",
      "Epoch 235: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6347 - f1_metric: 0.7040 - val_loss: 0.6590 - val_f1_metric: 0.7016 - lr: 1.0000e-04\n",
      "Epoch 236/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6232 - f1_metric: 0.7181\n",
      "Epoch 236: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6229 - f1_metric: 0.7177 - val_loss: 0.6589 - val_f1_metric: 0.6995 - lr: 1.0000e-04\n",
      "Epoch 237/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6348 - f1_metric: 0.7017\n",
      "Epoch 237: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6303 - f1_metric: 0.7055 - val_loss: 0.6590 - val_f1_metric: 0.7015 - lr: 1.0000e-04\n",
      "Epoch 238/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6209 - f1_metric: 0.7221\n",
      "Epoch 238: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6218 - f1_metric: 0.7243 - val_loss: 0.6584 - val_f1_metric: 0.7015 - lr: 1.0000e-04\n",
      "Epoch 239/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6288 - f1_metric: 0.7085\n",
      "Epoch 239: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6265 - f1_metric: 0.7080 - val_loss: 0.6589 - val_f1_metric: 0.7015 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6256 - f1_metric: 0.7121\n",
      "Epoch 240: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6252 - f1_metric: 0.7129 - val_loss: 0.6592 - val_f1_metric: 0.6991 - lr: 1.0000e-04\n",
      "Epoch 241/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6311 - f1_metric: 0.7072\n",
      "Epoch 241: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6299 - f1_metric: 0.7059 - val_loss: 0.6599 - val_f1_metric: 0.7025 - lr: 1.0000e-04\n",
      "Epoch 242/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.6175 - f1_metric: 0.7310\n",
      "Epoch 242: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6159 - f1_metric: 0.7330 - val_loss: 0.6589 - val_f1_metric: 0.7037 - lr: 1.0000e-04\n",
      "Epoch 243/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.6353 - f1_metric: 0.6950\n",
      "Epoch 243: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6273 - f1_metric: 0.7043 - val_loss: 0.6587 - val_f1_metric: 0.7033 - lr: 1.0000e-04\n",
      "Epoch 244/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.6164 - f1_metric: 0.7242\n",
      "Epoch 244: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6198 - f1_metric: 0.7190 - val_loss: 0.6591 - val_f1_metric: 0.7005 - lr: 1.0000e-04\n",
      "Epoch 245/10000\n",
      "49/67 [====================>.........] - ETA: 0s - loss: 0.6171 - f1_metric: 0.7158\n",
      "Epoch 245: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6219 - f1_metric: 0.7196 - val_loss: 0.6586 - val_f1_metric: 0.7002 - lr: 1.0000e-04\n",
      "Epoch 246/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.6189 - f1_metric: 0.7114\n",
      "Epoch 246: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6201 - f1_metric: 0.7116 - val_loss: 0.6587 - val_f1_metric: 0.6955 - lr: 1.0000e-04\n",
      "Epoch 247/10000\n",
      "51/67 [=====================>........] - ETA: 0s - loss: 0.6307 - f1_metric: 0.7039\n",
      "Epoch 247: val_loss did not improve from 0.65800\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6297 - f1_metric: 0.7062 - val_loss: 0.6584 - val_f1_metric: 0.6987 - lr: 1.0000e-04\n",
      "Epoch 248/10000\n",
      "50/67 [=====================>........] - ETA: 0s - loss: 0.6202 - f1_metric: 0.7246\n",
      "Epoch 248: val_loss improved from 0.65800 to 0.65788, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6246 - f1_metric: 0.7252 - val_loss: 0.6579 - val_f1_metric: 0.6987 - lr: 1.0000e-04\n",
      "Epoch 249/10000\n",
      "53/67 [======================>.......] - ETA: 0s - loss: 0.6271 - f1_metric: 0.7104\n",
      "Epoch 249: val_loss improved from 0.65788 to 0.65770, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6257 - f1_metric: 0.7120 - val_loss: 0.6577 - val_f1_metric: 0.6950 - lr: 1.0000e-04\n",
      "Epoch 250/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6231 - f1_metric: 0.7132\n",
      "Epoch 250: val_loss improved from 0.65770 to 0.65744, saving model to best_nn_model.h5\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6212 - f1_metric: 0.7150 - val_loss: 0.6574 - val_f1_metric: 0.6950 - lr: 1.0000e-04\n",
      "Epoch 251/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6262 - f1_metric: 0.7038\n",
      "Epoch 251: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6252 - f1_metric: 0.7054 - val_loss: 0.6584 - val_f1_metric: 0.6960 - lr: 1.0000e-04\n",
      "Epoch 252/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6264 - f1_metric: 0.7162\n",
      "Epoch 252: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6271 - f1_metric: 0.7155 - val_loss: 0.6583 - val_f1_metric: 0.6989 - lr: 1.0000e-04\n",
      "Epoch 253/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6142 - f1_metric: 0.7225\n",
      "Epoch 253: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6171 - f1_metric: 0.7200 - val_loss: 0.6584 - val_f1_metric: 0.7030 - lr: 1.0000e-04\n",
      "Epoch 254/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.6127 - f1_metric: 0.7225\n",
      "Epoch 254: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6173 - f1_metric: 0.7151 - val_loss: 0.6588 - val_f1_metric: 0.7031 - lr: 1.0000e-04\n",
      "Epoch 255/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6219 - f1_metric: 0.7039\n",
      "Epoch 255: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6230 - f1_metric: 0.7074 - val_loss: 0.6583 - val_f1_metric: 0.7020 - lr: 1.0000e-04\n",
      "Epoch 256/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6113 - f1_metric: 0.7260\n",
      "Epoch 256: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6173 - f1_metric: 0.7159 - val_loss: 0.6585 - val_f1_metric: 0.7041 - lr: 1.0000e-04\n",
      "Epoch 257/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6207 - f1_metric: 0.7050\n",
      "Epoch 257: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6192 - f1_metric: 0.7039 - val_loss: 0.6589 - val_f1_metric: 0.7032 - lr: 1.0000e-04\n",
      "Epoch 258/10000\n",
      "63/67 [===========================>..] - ETA: 0s - loss: 0.6213 - f1_metric: 0.7155\n",
      "Epoch 258: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6186 - f1_metric: 0.7173 - val_loss: 0.6593 - val_f1_metric: 0.7001 - lr: 1.0000e-04\n",
      "Epoch 259/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6143 - f1_metric: 0.7130\n",
      "Epoch 259: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6143 - f1_metric: 0.7094 - val_loss: 0.6592 - val_f1_metric: 0.6983 - lr: 1.0000e-04\n",
      "Epoch 260/10000\n",
      "47/67 [====================>.........] - ETA: 0s - loss: 0.6400 - f1_metric: 0.7055\n",
      "Epoch 260: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6325 - f1_metric: 0.7101 - val_loss: 0.6594 - val_f1_metric: 0.6978 - lr: 1.0000e-04\n",
      "Epoch 261/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6173 - f1_metric: 0.7174\n",
      "Epoch 261: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6151 - f1_metric: 0.7204 - val_loss: 0.6592 - val_f1_metric: 0.6967 - lr: 1.0000e-04\n",
      "Epoch 262/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6220 - f1_metric: 0.7132\n",
      "Epoch 262: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6225 - f1_metric: 0.7106 - val_loss: 0.6592 - val_f1_metric: 0.6977 - lr: 1.0000e-04\n",
      "Epoch 263/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6033 - f1_metric: 0.7300\n",
      "Epoch 263: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6059 - f1_metric: 0.7234 - val_loss: 0.6593 - val_f1_metric: 0.7021 - lr: 1.0000e-04\n",
      "Epoch 264/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6156 - f1_metric: 0.7173\n",
      "Epoch 264: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6167 - f1_metric: 0.7153 - val_loss: 0.6593 - val_f1_metric: 0.7006 - lr: 1.0000e-04\n",
      "Epoch 265/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6132 - f1_metric: 0.7157\n",
      "Epoch 265: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6157 - f1_metric: 0.7131 - val_loss: 0.6596 - val_f1_metric: 0.6924 - lr: 1.0000e-04\n",
      "Epoch 266/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6241 - f1_metric: 0.7087\n",
      "Epoch 266: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6244 - f1_metric: 0.7071 - val_loss: 0.6593 - val_f1_metric: 0.6953 - lr: 1.0000e-04\n",
      "Epoch 267/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6194 - f1_metric: 0.7161\n",
      "Epoch 267: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6173 - f1_metric: 0.7162 - val_loss: 0.6587 - val_f1_metric: 0.6931 - lr: 1.0000e-04\n",
      "Epoch 268/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6210 - f1_metric: 0.7054\n",
      "Epoch 268: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6185 - f1_metric: 0.7068 - val_loss: 0.6590 - val_f1_metric: 0.6924 - lr: 1.0000e-04\n",
      "Epoch 269/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6201 - f1_metric: 0.7116\n",
      "Epoch 269: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6198 - f1_metric: 0.7138 - val_loss: 0.6592 - val_f1_metric: 0.6934 - lr: 1.0000e-04\n",
      "Epoch 270/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6116 - f1_metric: 0.7238\n",
      "Epoch 270: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6147 - f1_metric: 0.7230 - val_loss: 0.6589 - val_f1_metric: 0.6934 - lr: 1.0000e-04\n",
      "Epoch 271/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6127 - f1_metric: 0.7075\n",
      "Epoch 271: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6102 - f1_metric: 0.7127 - val_loss: 0.6594 - val_f1_metric: 0.6914 - lr: 1.0000e-04\n",
      "Epoch 272/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6169 - f1_metric: 0.7200\n",
      "Epoch 272: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6207 - f1_metric: 0.7120 - val_loss: 0.6589 - val_f1_metric: 0.6915 - lr: 1.0000e-04\n",
      "Epoch 273/10000\n",
      "54/67 [=======================>......] - ETA: 0s - loss: 0.5996 - f1_metric: 0.7320\n",
      "Epoch 273: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6069 - f1_metric: 0.7241 - val_loss: 0.6592 - val_f1_metric: 0.6905 - lr: 1.0000e-04\n",
      "Epoch 274/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6112 - f1_metric: 0.7223\n",
      "Epoch 274: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6125 - f1_metric: 0.7232 - val_loss: 0.6596 - val_f1_metric: 0.6902 - lr: 1.0000e-04\n",
      "Epoch 275/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6142 - f1_metric: 0.7149\n",
      "Epoch 275: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6126 - f1_metric: 0.7130 - val_loss: 0.6601 - val_f1_metric: 0.6925 - lr: 1.0000e-04\n",
      "Epoch 276/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6229 - f1_metric: 0.7142\n",
      "Epoch 276: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6183 - f1_metric: 0.7193 - val_loss: 0.6595 - val_f1_metric: 0.6914 - lr: 1.0000e-04\n",
      "Epoch 277/10000\n",
      "54/67 [=======================>......] - ETA: 0s - loss: 0.6170 - f1_metric: 0.7159\n",
      "Epoch 277: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6101 - f1_metric: 0.7205 - val_loss: 0.6607 - val_f1_metric: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 278/10000\n",
      "66/67 [============================>.] - ETA: 0s - loss: 0.6064 - f1_metric: 0.7259\n",
      "Epoch 278: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6068 - f1_metric: 0.7250 - val_loss: 0.6594 - val_f1_metric: 0.6930 - lr: 1.0000e-04\n",
      "Epoch 279/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.6238 - f1_metric: 0.7049\n",
      "Epoch 279: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6203 - f1_metric: 0.7064 - val_loss: 0.6593 - val_f1_metric: 0.6895 - lr: 1.0000e-04\n",
      "Epoch 280/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6173 - f1_metric: 0.7068\n",
      "Epoch 280: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6126 - f1_metric: 0.7096 - val_loss: 0.6587 - val_f1_metric: 0.6876 - lr: 1.0000e-04\n",
      "Epoch 281/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.6069 - f1_metric: 0.7165\n",
      "Epoch 281: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6074 - f1_metric: 0.7194 - val_loss: 0.6583 - val_f1_metric: 0.6886 - lr: 1.0000e-04\n",
      "Epoch 282/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6121 - f1_metric: 0.7217\n",
      "Epoch 282: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6137 - f1_metric: 0.7225 - val_loss: 0.6584 - val_f1_metric: 0.6879 - lr: 1.0000e-04\n",
      "Epoch 283/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6041 - f1_metric: 0.7341\n",
      "Epoch 283: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6044 - f1_metric: 0.7288 - val_loss: 0.6591 - val_f1_metric: 0.6962 - lr: 1.0000e-04\n",
      "Epoch 284/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6039 - f1_metric: 0.7182\n",
      "Epoch 284: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6038 - f1_metric: 0.7167 - val_loss: 0.6603 - val_f1_metric: 0.6976 - lr: 1.0000e-04\n",
      "Epoch 285/10000\n",
      "52/67 [======================>.......] - ETA: 0s - loss: 0.5990 - f1_metric: 0.7257\n",
      "Epoch 285: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6060 - f1_metric: 0.7181 - val_loss: 0.6600 - val_f1_metric: 0.6985 - lr: 1.0000e-04\n",
      "Epoch 286/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6126 - f1_metric: 0.7235\n",
      "Epoch 286: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6133 - f1_metric: 0.7189 - val_loss: 0.6601 - val_f1_metric: 0.6985 - lr: 1.0000e-04\n",
      "Epoch 287/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6091 - f1_metric: 0.7262\n",
      "Epoch 287: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6055 - f1_metric: 0.7308 - val_loss: 0.6602 - val_f1_metric: 0.6996 - lr: 1.0000e-04\n",
      "Epoch 288/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6136 - f1_metric: 0.7130\n",
      "Epoch 288: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6150 - f1_metric: 0.7111 - val_loss: 0.6598 - val_f1_metric: 0.6988 - lr: 1.0000e-04\n",
      "Epoch 289/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6132 - f1_metric: 0.7147\n",
      "Epoch 289: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6109 - f1_metric: 0.7192 - val_loss: 0.6597 - val_f1_metric: 0.6940 - lr: 1.0000e-04\n",
      "Epoch 290/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6120 - f1_metric: 0.7270\n",
      "Epoch 290: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6092 - f1_metric: 0.7300 - val_loss: 0.6585 - val_f1_metric: 0.6933 - lr: 1.0000e-04\n",
      "Epoch 291/10000\n",
      "56/67 [========================>.....] - ETA: 0s - loss: 0.6102 - f1_metric: 0.7124\n",
      "Epoch 291: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6098 - f1_metric: 0.7175 - val_loss: 0.6583 - val_f1_metric: 0.6958 - lr: 1.0000e-04\n",
      "Epoch 292/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6091 - f1_metric: 0.7370\n",
      "Epoch 292: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6088 - f1_metric: 0.7339 - val_loss: 0.6590 - val_f1_metric: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 293/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.5961 - f1_metric: 0.7305\n",
      "Epoch 293: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6030 - f1_metric: 0.7257 - val_loss: 0.6594 - val_f1_metric: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 294/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.6015 - f1_metric: 0.7325\n",
      "Epoch 294: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6048 - f1_metric: 0.7216 - val_loss: 0.6592 - val_f1_metric: 0.6946 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6111 - f1_metric: 0.7289\n",
      "Epoch 295: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6047 - f1_metric: 0.7356 - val_loss: 0.6593 - val_f1_metric: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 296/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6027 - f1_metric: 0.7252\n",
      "Epoch 296: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5991 - f1_metric: 0.7264 - val_loss: 0.6595 - val_f1_metric: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 297/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6047 - f1_metric: 0.7230\n",
      "Epoch 297: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6029 - f1_metric: 0.7257 - val_loss: 0.6586 - val_f1_metric: 0.6965 - lr: 1.0000e-04\n",
      "Epoch 298/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.5981 - f1_metric: 0.7419\n",
      "Epoch 298: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5988 - f1_metric: 0.7394 - val_loss: 0.6593 - val_f1_metric: 0.6974 - lr: 1.0000e-04\n",
      "Epoch 299/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6084 - f1_metric: 0.7276\n",
      "Epoch 299: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6086 - f1_metric: 0.7242 - val_loss: 0.6599 - val_f1_metric: 0.6975 - lr: 1.0000e-04\n",
      "Epoch 300/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6134 - f1_metric: 0.7206\n",
      "Epoch 300: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6102 - f1_metric: 0.7241 - val_loss: 0.6596 - val_f1_metric: 0.6948 - lr: 1.0000e-04\n",
      "Epoch 301/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.5971 - f1_metric: 0.7287\n",
      "Epoch 301: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5951 - f1_metric: 0.7331 - val_loss: 0.6590 - val_f1_metric: 0.6938 - lr: 1.0000e-04\n",
      "Epoch 302/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.5878 - f1_metric: 0.7370\n",
      "Epoch 302: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5895 - f1_metric: 0.7319 - val_loss: 0.6597 - val_f1_metric: 0.6966 - lr: 1.0000e-04\n",
      "Epoch 303/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.5993 - f1_metric: 0.7244\n",
      "Epoch 303: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5993 - f1_metric: 0.7265 - val_loss: 0.6597 - val_f1_metric: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 304/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.5912 - f1_metric: 0.7323\n",
      "Epoch 304: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5890 - f1_metric: 0.7314 - val_loss: 0.6606 - val_f1_metric: 0.6958 - lr: 1.0000e-04\n",
      "Epoch 305/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.5967 - f1_metric: 0.7271\n",
      "Epoch 305: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6020 - f1_metric: 0.7221 - val_loss: 0.6605 - val_f1_metric: 0.6971 - lr: 1.0000e-04\n",
      "Epoch 306/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.6025 - f1_metric: 0.7209\n",
      "Epoch 306: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6038 - f1_metric: 0.7193 - val_loss: 0.6602 - val_f1_metric: 0.6981 - lr: 1.0000e-04\n",
      "Epoch 307/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.5989 - f1_metric: 0.7315\n",
      "Epoch 307: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6006 - f1_metric: 0.7284 - val_loss: 0.6599 - val_f1_metric: 0.7011 - lr: 1.0000e-04\n",
      "Epoch 308/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.5949 - f1_metric: 0.7275\n",
      "Epoch 308: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5950 - f1_metric: 0.7302 - val_loss: 0.6593 - val_f1_metric: 0.7011 - lr: 1.0000e-04\n",
      "Epoch 309/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6037 - f1_metric: 0.7230\n",
      "Epoch 309: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5979 - f1_metric: 0.7258 - val_loss: 0.6602 - val_f1_metric: 0.7029 - lr: 1.0000e-04\n",
      "Epoch 310/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6052 - f1_metric: 0.7263\n",
      "Epoch 310: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5991 - f1_metric: 0.7329 - val_loss: 0.6595 - val_f1_metric: 0.6963 - lr: 1.0000e-04\n",
      "Epoch 311/10000\n",
      "55/67 [=======================>......] - ETA: 0s - loss: 0.6051 - f1_metric: 0.7179\n",
      "Epoch 311: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5992 - f1_metric: 0.7259 - val_loss: 0.6587 - val_f1_metric: 0.7002 - lr: 1.0000e-04\n",
      "Epoch 312/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.5935 - f1_metric: 0.7415\n",
      "Epoch 312: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5919 - f1_metric: 0.7399 - val_loss: 0.6589 - val_f1_metric: 0.6994 - lr: 1.0000e-04\n",
      "Epoch 313/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.5955 - f1_metric: 0.7250\n",
      "Epoch 313: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5991 - f1_metric: 0.7261 - val_loss: 0.6600 - val_f1_metric: 0.6991 - lr: 1.0000e-04\n",
      "Epoch 314/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.5872 - f1_metric: 0.7310\n",
      "Epoch 314: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5906 - f1_metric: 0.7293 - val_loss: 0.6595 - val_f1_metric: 0.6957 - lr: 1.0000e-04\n",
      "Epoch 315/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.6031 - f1_metric: 0.7264\n",
      "Epoch 315: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6020 - f1_metric: 0.7255 - val_loss: 0.6596 - val_f1_metric: 0.6951 - lr: 1.0000e-04\n",
      "Epoch 316/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.5855 - f1_metric: 0.7420\n",
      "Epoch 316: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5893 - f1_metric: 0.7360 - val_loss: 0.6602 - val_f1_metric: 0.7021 - lr: 1.0000e-04\n",
      "Epoch 317/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.5895 - f1_metric: 0.7311\n",
      "Epoch 317: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5910 - f1_metric: 0.7281 - val_loss: 0.6603 - val_f1_metric: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 318/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.5919 - f1_metric: 0.7261\n",
      "Epoch 318: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5869 - f1_metric: 0.7321 - val_loss: 0.6602 - val_f1_metric: 0.6981 - lr: 1.0000e-04\n",
      "Epoch 319/10000\n",
      "62/67 [==========================>...] - ETA: 0s - loss: 0.5862 - f1_metric: 0.7353\n",
      "Epoch 319: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5857 - f1_metric: 0.7374 - val_loss: 0.6599 - val_f1_metric: 0.6998 - lr: 1.0000e-04\n",
      "Epoch 320/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.5807 - f1_metric: 0.7362\n",
      "Epoch 320: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5833 - f1_metric: 0.7364 - val_loss: 0.6592 - val_f1_metric: 0.6961 - lr: 1.0000e-04\n",
      "Epoch 321/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.5938 - f1_metric: 0.7229\n",
      "Epoch 321: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5916 - f1_metric: 0.7276 - val_loss: 0.6595 - val_f1_metric: 0.7018 - lr: 1.0000e-04\n",
      "Epoch 322/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.5910 - f1_metric: 0.7285\n",
      "Epoch 322: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5926 - f1_metric: 0.7255 - val_loss: 0.6590 - val_f1_metric: 0.7018 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6076 - f1_metric: 0.7108\n",
      "Epoch 323: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.6087 - f1_metric: 0.7122 - val_loss: 0.6580 - val_f1_metric: 0.7002 - lr: 1.0000e-04\n",
      "Epoch 324/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.5841 - f1_metric: 0.7489\n",
      "Epoch 324: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5837 - f1_metric: 0.7467 - val_loss: 0.6588 - val_f1_metric: 0.6969 - lr: 1.0000e-04\n",
      "Epoch 325/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.5872 - f1_metric: 0.7412\n",
      "Epoch 325: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5901 - f1_metric: 0.7374 - val_loss: 0.6597 - val_f1_metric: 0.6987 - lr: 1.0000e-04\n",
      "Epoch 326/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.6005 - f1_metric: 0.7244\n",
      "Epoch 326: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5997 - f1_metric: 0.7265 - val_loss: 0.6595 - val_f1_metric: 0.6977 - lr: 1.0000e-04\n",
      "Epoch 327/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.5940 - f1_metric: 0.7277\n",
      "Epoch 327: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5957 - f1_metric: 0.7237 - val_loss: 0.6602 - val_f1_metric: 0.6986 - lr: 1.0000e-04\n",
      "Epoch 328/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.5857 - f1_metric: 0.7350\n",
      "Epoch 328: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5860 - f1_metric: 0.7346 - val_loss: 0.6601 - val_f1_metric: 0.7006 - lr: 1.0000e-04\n",
      "Epoch 329/10000\n",
      "60/67 [=========================>....] - ETA: 0s - loss: 0.5903 - f1_metric: 0.7264\n",
      "Epoch 329: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5940 - f1_metric: 0.7228 - val_loss: 0.6602 - val_f1_metric: 0.7014 - lr: 1.0000e-04\n",
      "Epoch 330/10000\n",
      "57/67 [========================>.....] - ETA: 0s - loss: 0.5787 - f1_metric: 0.7351\n",
      "Epoch 330: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5825 - f1_metric: 0.7299 - val_loss: 0.6605 - val_f1_metric: 0.6990 - lr: 1.0000e-04\n",
      "Epoch 331/10000\n",
      "59/67 [=========================>....] - ETA: 0s - loss: 0.5888 - f1_metric: 0.7374\n",
      "Epoch 331: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5853 - f1_metric: 0.7419 - val_loss: 0.6590 - val_f1_metric: 0.7010 - lr: 1.0000e-04\n",
      "Epoch 332/10000\n",
      "58/67 [========================>.....] - ETA: 0s - loss: 0.5872 - f1_metric: 0.7373\n",
      "Epoch 332: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5887 - f1_metric: 0.7327 - val_loss: 0.6598 - val_f1_metric: 0.7000 - lr: 1.0000e-04\n",
      "Epoch 333/10000\n",
      "61/67 [==========================>...] - ETA: 0s - loss: 0.5819 - f1_metric: 0.7345\n",
      "Epoch 333: val_loss did not improve from 0.65744\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5851 - f1_metric: 0.7309 - val_loss: 0.6607 - val_f1_metric: 0.6990 - lr: 1.0000e-04\n",
      "Loading best neural network model...\n",
      "Saving neural network model...\n",
      "Initializing BaggingClassifier with best parameters...\n",
      "Training BaggingClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bapti\\AppData\\Local\\Temp\\ipykernel_1520\\1686237341.py:93: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(nn_model, nn_model_path)\n",
      "C:\\Users\\bapti\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving BaggingClassifier model...\n",
      "Loading test data...\n",
      "Test data loaded.\n",
      "Normalizing test data...\n",
      "Test data normalized.\n",
      "Making predictions with the BaggingClassifier model...\n",
      "Saving predictions...\n",
      "Predictions saved to predictions.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "import joblib\n",
    "\n",
    "# Register custom metric with Keras\n",
    "def f1_metric(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1 - y_true) * (1 - y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2 * p * r / (p + r + K.epsilon())\n",
    "    return K.mean(f1)\n",
    "\n",
    "get_custom_objects().update({\"f1_metric\": f1_metric})\n",
    "\n",
    "# Global Variables\n",
    "dropout_value = 0.5\n",
    "epochs_value = 10000\n",
    "patience_value = 100\n",
    "random_state_value = 50\n",
    "\n",
    "# Load the training data\n",
    "print(\"Loading training data...\")\n",
    "train_file_path = 'train.csv'  # replace with your actual file path\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "print(\"Training data loaded.\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_data.drop(columns=['Target'])\n",
    "y_train = train_data['Target']\n",
    "\n",
    "# Handle missing values\n",
    "X_train = X_train.fillna(X_train.mean())\n",
    "\n",
    "# Normalize the features\n",
    "print(\"Normalizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "print(\"Features normalized.\")\n",
    "\n",
    "# Build the neural network model\n",
    "print(\"Building neural network model...\")\n",
    "def build_nn_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_value))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_value))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_value))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=[f1_metric])\n",
    "    return model\n",
    "\n",
    "# Initialize the neural network model\n",
    "nn_model = build_nn_model(X_train_scaled.shape[1])\n",
    "\n",
    "# Train the neural network model\n",
    "print(\"Training neural network model...\")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_value, restore_best_weights=True, min_delta=0.001)\n",
    "model_checkpoint = ModelCheckpoint('best_nn_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001, verbose=1)\n",
    "\n",
    "history = nn_model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=epochs_value, batch_size=32, callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "\n",
    "# Load the best neural network model\n",
    "print(\"Loading best neural network model...\")\n",
    "nn_model.load_weights('best_nn_model.h5')\n",
    "\n",
    "# Save the neural network model\n",
    "print(\"Saving neural network model...\")\n",
    "nn_model_path = \"neural_network_model.h5\"\n",
    "save_model(nn_model, nn_model_path)\n",
    "\n",
    "# Initialize the BaggingClassifier with best parameters\n",
    "print(\"Initializing BaggingClassifier with best parameters...\")\n",
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=RandomForestClassifier(\n",
    "        criterion='gini',\n",
    "        max_depth=8,\n",
    "        max_features='log2',\n",
    "        n_estimators=100,\n",
    "        random_state=random_state_value\n",
    "    ),\n",
    "    n_estimators=10,\n",
    "    random_state=random_state_value\n",
    ")\n",
    "\n",
    "# Train the BaggingClassifier\n",
    "print(\"Training BaggingClassifier...\")\n",
    "bagging_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the BaggingClassifier model\n",
    "print(\"Saving BaggingClassifier model...\")\n",
    "bagging_model_path = \"bagging_classifier_model.pkl\"\n",
    "joblib.dump(bagging_clf, bagging_model_path)\n",
    "\n",
    "# Load the test data\n",
    "print(\"Loading test data...\")\n",
    "test_file_path = 'test.csv'  # replace with your actual file path\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "print(\"Test data loaded.\")\n",
    "\n",
    "# Handle missing values in the test data\n",
    "X_test = test_data.fillna(test_data.mean())\n",
    "\n",
    "# Normalize the test data\n",
    "print(\"Normalizing test data...\")\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Test data normalized.\")\n",
    "\n",
    "# Make predictions with the BaggingClassifier model\n",
    "print(\"Making predictions with the BaggingClassifier model...\")\n",
    "y_pred_bagging = bagging_clf.predict(X_test_scaled)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "print(\"Saving predictions...\")\n",
    "output = pd.DataFrame({'ID': test_data['ID'], 'Target': y_pred_bagging})\n",
    "output.to_csv('predictions.csv', index=False)\n",
    "print(\"Predictions saved to predictions.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7138b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
